{
  "date": "Tuesday July 14th, 2019",
  "title": "Sounds Aware (2019)",
  "body": "Sounds Aware is a web application that runs on a smartphone and uses machine learning to detect human-made sound (anthrophony) and masks it with ambient music as a user walks around their environment. Though the model is pre-trained with the author’s local environmental sounds, the user can train the model further on their unique soundscape so that each user gets a personalized experience. After the training process, the user can listen to ambient music based on traits of the surrounding anthrophony. If the app senses less anthrophony and more biophony or geophony, then the music fades away, bringing the user’s attention to the anthrophony.\n\n[App](https://soundsaware.com) | [Paper](https://www.tatecarson.com/assets/papers/SoundsAware_CameraReady.pdf) | [Code](https://github.com/tatecarson/walking-machine-listening)\n\n<!--EndFragment-->\n\n## Presentation at Web Audio Conference 2019 (Norwegian University of Science and Technology, Trondheim, Norway)\n\n### Talk\n\n<iframe width=\"100%\" height=\"600\" src=\"https://www.youtube.com/embed/4ZdOdbysd9c\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n*Note: There was a glitch with the video recording that caused my voice to sound lower.* \n\n### Poster\n\n![](/images/uploads/sounds-aware/posterpresentation.jpg)",
  "category": "Smartphone",
  "thumbnail": "/images/uploads/nature3.jpeg"
}